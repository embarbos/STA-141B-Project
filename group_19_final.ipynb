{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group 19 Final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tweet_df Acquisition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import requests\n",
    "import twint\n",
    "import nest_asyncio\n",
    "import json\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "from nltk.corpus import wordnet\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('omw-1.4')\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c = twint.Config()\n",
    "# c.Search = 'Nuclear Energy'\n",
    "# c.Limit = 5000\n",
    "# c.Store_json = True\n",
    "# c.Output = 'twit_data.json'\n",
    "# twint.run.Search(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c = twint.Config()\n",
    "# c.Search = 'Nuclear Power'\n",
    "# c.Limit = 5000\n",
    "# c.Store_json = True\n",
    "# c.Output = 'twit_data.json'\n",
    "# twint.run.Search(c)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataremoved Cleaning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(r'twit_data.json', 'rb')\n",
    "data = [json.loads(line) for line in f]\n",
    "tweet_df = pd.DataFrame(data)\n",
    "tweet_df = tweet_df[['tweet','link']]\n",
    "tweet_df = tweet_df.drop_duplicates()\n",
    "dataremoved = tweet_df[~tweet_df.iloc[:,0].str.contains('Ukraine')]\n",
    "dataremoved = dataremoved[~dataremoved.iloc[:,0].str.contains('ukraine')]\n",
    "dataremoved = dataremoved[~dataremoved.iloc[:,0].str.contains('Ukrainian')]\n",
    "dataremoved = dataremoved[~dataremoved.iloc[:,0].str.contains('ukrainian')]\n",
    "dataremoved = dataremoved[~dataremoved.iloc[:,0].str.contains('Ukrainians')]\n",
    "dataremoved = dataremoved[~dataremoved.iloc[:,0].str.contains('ukrainians')]\n",
    "dataremoved = dataremoved[~dataremoved.iloc[:,0].str.contains('Zaporizhzhia')]\n",
    "dataremoved = dataremoved[~dataremoved.iloc[:,0].str.contains('war')]\n",
    "dataremoved = dataremoved[~dataremoved.iloc[:,0].str.contains('russia')]\n",
    "dataremoved = dataremoved[~dataremoved.iloc[:,0].str.contains('Russia')]\n",
    "dataremoved = dataremoved[~dataremoved.iloc[:,0].str.contains('russian')]\n",
    "dataremoved = dataremoved[~dataremoved.iloc[:,0].str.contains('Russian')]\n",
    "dataremoved = dataremoved[~dataremoved.iloc[:,0].str.contains('russians')]\n",
    "dataremoved = dataremoved[~dataremoved.iloc[:,0].str.contains('Russians')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_tweets = []\n",
    "words = []\n",
    "for tweet in dataremoved['tweet']:\n",
    "    clean = re.sub(r\"(http[s]?\\://\\S+)|([\\[\\(].*[\\)\\]])|([#@]\\S+)|\\n\", \"\", tweet)\n",
    "    clean = re.sub(r\"\\d\", '', clean)\n",
    "    clean = re.sub(r\"'\\S+\", '', clean)\n",
    "    clean = clean.replace('.', '').replace(';', '').lower()\n",
    "    words += re.findall(r\"(?:\\w+|'|â€™)+\", clean)\n",
    "    cleaned_tweets.append(clean)\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "standardized = [w for w in words if w not in stopwords]\n",
    "\n",
    "# removing other symbols\n",
    "corpus = [[re.sub('[^a-zA-Z ]', ' ', document)] for document in cleaned_tweets]\n",
    "#tokenizing\n",
    "corpus_tokenized = [nltk.word_tokenize(document[0]) for document in corpus]\n",
    "# stop words\n",
    "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "corpus_tokenized = [[word for word in document if word not in stopwords] for document in corpus_tokenized]\n",
    "# lemmatizing\n",
    "nltk.download('wordnet')\n",
    "corpus_lemmatized = [[nltk.WordNetLemmatizer().lemmatize(word) for word in document] for document in corpus_tokenized]\n",
    "# stitching back together\n",
    "corpus = [' '.join(document) for document in corpus_lemmatized]\n",
    "# string obj for VADER\n",
    "corpus_string = \"\"\n",
    "for tweet in corpus:\n",
    "    corpus_string += tweet[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(another cleaning method-- on a per tweet basis. we need to sort this out w/ the code above.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all.csv is in the github, it is all of the tweets including the training set tweets we worked on, with the ukraine/russian/war tweets filtered out\n",
    "data = pd.read_csv('all.csv',header=None)\n",
    "data = data.iloc[:,1]\n",
    "data.columns = ['tweets']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Model: Preliminary LDA\n",
    "\n",
    "We will be using the gensim package's LDA model because it seems to have more LDA-specific features such as coherence score calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "#import spacy\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "#import pyLDAvis\n",
    "#import pyLDAvis.gensim_models\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(corpus_lemmatized)\n",
    "doc_term_matrix = [dictionary.doc2bow(rev) for rev in corpus_lemmatized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA = gensim.models.ldamodel.LdaModel\n",
    "\n",
    "# Build LDA model\n",
    "lda_model = LDA(corpus=doc_term_matrix, id2word=dictionary, num_topics=2, random_state=100,\n",
    "                chunksize=1000, passes=50,iterations=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topic display\n",
    "posterior = lda_model.print_topics()\n",
    "two_topic_LDA = pd.DataFrame(posterior)[1]\n",
    "two_topic_LDA = two_topic_LDA.transpose()\n",
    "two_topic_LDA.index = ['topic ' + str(i) for i in range(0,2)]\n",
    "two_topic_LDA.name = 'words'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perplexity and coherence scores\n",
    "\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(doc_term_matrix,total_docs=10000))  # a measure of how good the model is. lower the better.\n",
    "# Compute Coherence Score\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=corpus_lemmatized, dictionary=dictionary , coherence='u_mass')\n",
    "if __name__ == \"__main__\":\n",
    "    #freeze_support()\n",
    "    coherence_lda = coherence_model_lda.get_coherence()\n",
    "    print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to identify what number of LDA topics would work best as an input to k-NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% GRAPH FUNCTION\n",
    "\n",
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = LDA(corpus=corpus, num_topics=num_topics, id2word=dictionary)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='u_mass')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build list of scores across different topic numbers\n",
    "\n",
    "model_list, coherence_values = compute_coherence_values(dictionary=dictionary, corpus=doc_term_matrix, texts=corpus_lemmatized, start=2, limit=50, step=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show graph\n",
    "limit=50; start=2; step=1;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the coherence scores\n",
    "for m, cv in zip(x, coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimal number = 2??? hahahaha\n",
    "\n",
    "INTERACTIVE ELEMENT CAN GO HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "vis_data = pyLDAvis.gensim_models.prepare(lda_model, doc_term_matrix, dictionary)\n",
    "pyLDAvis.show(vis_data, open_browser=False, local=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% MATRIX TIME, THIS OUTPUT WILL GO INTO K-NN\n",
    "\n",
    "tweet_vectors = pd.Series(0)\n",
    "for i in range(len(doc_term_matrix)):    \n",
    "    tweet_vectors[i] = lda_model.get_document_topics(doc_term_matrix[i], minimum_probability=0, minimum_phi_value=None, per_word_topics=False)\n",
    "\n",
    "tweet_vectors_entries = [[tweet_vectors[i][0][1],tweet_vectors[i][1][1]] for i in range(len(tweet_vectors))]\n",
    "\n",
    "LDA_tweet_frame = pd.DataFrame(tweet_vectors_entries, columns = ['Topic 0','Topic 1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Model: K-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import Binarizer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames=['tweets', 'label']\n",
    "data = pd.read_csv(\"labelled.csv\", names=colnames, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding_tweets(data):\n",
    "    # 1. create a CountVectorizer\n",
    "    vec = CountVectorizer(tokenizer = nltk.word_tokenize)\n",
    "    # convert the type of \"tweets\" to str\n",
    "    data[\"tweets\"] = data[\"tweets\"].astype(str)\n",
    "    tweet_list = list(data['tweets'])\n",
    "    freq = vec.fit_transform(tweet_list)\n",
    "    # create one-hot encoding\n",
    "    ohot = Binarizer().fit_transform(freq)\n",
    "    # one-hot encoding\n",
    "    corpus_binary = ohot.todense()\n",
    "\n",
    "    # convert matrix to dataframe\n",
    "    encoder_df = pd.DataFrame(corpus_binary)\n",
    "\n",
    "    # create x and y for knn\n",
    "    x = encoder_df\n",
    "    y = data['label']\n",
    "\n",
    "    return x,y\n",
    "\n",
    "\n",
    "# create x, y for knn\n",
    "x = one_hot_encoding_tweets(data)[0]\n",
    "y = one_hot_encoding_tweets(data)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the optimal k for the accuracy\n",
    "k_range = range(1, 31)\n",
    "k_error = []\n",
    "k_acc = []\n",
    "optimal_k = 0\n",
    "min_error = 1\n",
    "max_acc = 0\n",
    "\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    # the value of cv decides the ratio of training and testing data\n",
    "    scores = cross_val_score(knn, x, y, cv=4, scoring='accuracy')\n",
    "    # error rate\n",
    "    error_rate = 1 - scores.mean()\n",
    "    # record the best performance with value of k\n",
    "    if error_rate < min_error:\n",
    "        min_error = error_rate\n",
    "        optimal_k = k\n",
    "        max_acc = scores.mean()\n",
    "    k_error.append(error_rate)\n",
    "    # accuracy rate\n",
    "    k_acc.append(scores.mean())\n",
    "\n",
    "# plot: x is the k value, y is the error value\n",
    "plt.plot(k_range, k_error)\n",
    "plt.xlabel('Value of K for KNN')\n",
    "plt.ylabel('Cross-Validated Error')\n",
    "plt.show()\n",
    "print(\"the optimal k is: \", optimal_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the effect of random_state for accuracy\n",
    "\n",
    "# Import train_test_split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "# Split dataset into training set and test set\n",
    "# test which test_size produces the largest acc\n",
    "test_size_range = range(0.1,0.4,0.1)\n",
    "acc = 0\n",
    "test_size_acc = []\n",
    "test_size = []\n",
    "for size in test_size_range:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=size, random_state=0) # 80% training and 20% test\n",
    "    # Create KNN Classifier\n",
    "    knn = KNeighborsClassifier(n_neighbors=25)\n",
    "\n",
    "    # Train the model using the training sets\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    # Predict the response for test dataset\n",
    "    y_pred = knn.predict(X_test)\n",
    "    # Model Accuracy, how often is the classifier correct?\n",
    "    # calculate the accuracy\n",
    "    acc_s = metrics.accuracy_score(y_test, y_pred)\n",
    "    if acc <= acc_s:\n",
    "        acc = acc_s\n",
    "        print(\"test_size: \", size)\n",
    "        print(\"Accuracy:\", acc)\n",
    "        test_size_acc.append(acc)\n",
    "        test_size.append(size)\n",
    "\n",
    "plt.plot(test_size, test_size_acc)\n",
    "plt.xlabel('Test Size')\n",
    "plt.ylabel('acc for KNN')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict lables for test data using training data\n",
    "def pred_label_for_test(train_data, data_test):\n",
    "    merge_data = train_data.append(data_test, ignore_index=True)\n",
    "\n",
    "    # %% for\n",
    "    x = one_hot_encoding_tweets(merge_data)[0]\n",
    "    y = one_hot_encoding_tweets(merge_data)[1]\n",
    "    \n",
    "    # convert 'negative', 'neutral', 'positive' into 3,2,1     \n",
    "    enc = LabelEncoder()\n",
    "    label_encoder = enc.fit(y)\n",
    "    y = label_encoder.transform(y)\n",
    "\n",
    "    # %% for labelled.csv and remainder.csv\n",
    "    X_train = x.loc[:1174, :]\n",
    "    y_train = y[:1175]\n",
    "\n",
    "    X_test = x.loc[1175:, :]\n",
    "\n",
    "    # Create KNN Classifier\n",
    "    knn = KNeighborsClassifier(n_neighbors=10)\n",
    "\n",
    "    # Train the model using the training sets\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    # Predict the response for test dataset\n",
    "    y_pred = knn.predict(X_test)\n",
    "    \n",
    "    return y_pred, y_train\n",
    "\n",
    "\n",
    "# drawing bar plots for data\n",
    "def bar_plot_for_data(data_for_bar):\n",
    "    req = np.array(np.unique(data_for_bar, return_counts=True)).T\n",
    "    freq_data = sorted(\n",
    "                        [(name, float(val)) for name, val in freq],\n",
    "                         key=lambda x:x[1],\n",
    "                         reverse=True\n",
    "                        )\n",
    "\n",
    "    colors_list = ['Red', 'Orange', 'Blue']\n",
    "    p1 = plt.bar(*zip(*freq_data), color=colors_list)\n",
    "\n",
    "    n = len(data_for_bar)\n",
    "    for rect1 in p1:\n",
    "        height = rect1.get_height()\n",
    "        plt.annotate(\"{}%\".format(round(height/n, 2)), (rect1.get_x() + rect1.get_width()/2,\n",
    "                                            height+.05), ha=\"center\", va=\"bottom\", fontsize=15)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = ['tweets', 'label']\n",
    "data_labelled = pd.read_csv('labelled.csv', names=colnames, header=None)\n",
    "data_labelled_cleaned = pd.read_csv('labelled_cleaned.csv', names=colnames, header=None)\n",
    "colnames = ['tweets']\n",
    "data_test = pd.read_csv(\"remainder.csv\", names=colnames, header=None)\n",
    "data_test['label'] = \"\"   # add one empty column \"label\"\n",
    "\n",
    "# obtain the predication labels\n",
    "y_pred_labelled = pred_label_for_test(data_labelled, data_test)[0]\n",
    "y_pred_labelled_cleand = pred_label_for_test(data_labelled_cleaned, data_test)[0]\n",
    "\n",
    "# draw barplots\n",
    "bar_plot_for_data(y_pred_labelled)\n",
    "bar_plot_for_data(y_pred_labelled_cleand)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bar plots with percentages\n",
    "def pred_label_for_lda(train_lda, test_lda):\n",
    "    # %% for labelled_LDA_vectors.csv and remainder_LDA_vectors.csv\n",
    "    X_train = train_lda.loc[:1174, :1]\n",
    "    y_train = train_lda.loc[:1174, 2]\n",
    "    enc = LabelEncoder()\n",
    "    label_encoder = enc.fit(y_train)\n",
    "    y_train = label_encoder.transform(y_train)+1\n",
    "\n",
    "    X_test = test_lda.loc[1175:, :]\n",
    "\n",
    "    # Create KNN Classifier\n",
    "    knn = KNeighborsClassifier(n_neighbors=10)\n",
    "\n",
    "    # Train the model using the training sets\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    # Predict the response for test dataset\n",
    "    y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_stopw = pd.read_csv(\"labelled_LDA_vectors_withStopwords.csv\", header=None, skiprows=1)\n",
    "test_data_stopw = pd.read_csv(\"remainder_LDA_vectors_withStopwords.csv\", header=None, skiprows=1)\n",
    "\n",
    "train_data = pd.read_csv(\"labelled_LDA_vectors.csv\", header=None, skiprows=1)\n",
    "test_data = pd.read_csv(\"remainder_LDA_vectors.csv\", header=None, skiprows=1)\n",
    "\n",
    "# obtain the predication labels\n",
    "y_pred_lda = pred_label_for_lda(train_data_stopw, test_data_stopw)[0]\n",
    "y_pred_lda_cleand = pred_label_for_lda(train_data, test_data)[0]\n",
    "\n",
    "# draw barplots\n",
    "bar_plot_for_data(y_pred_lda)\n",
    "bar_plot_for_data(y_pred_lda_cleand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third Model: VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_words = word_tokenize(corpus_string, \"english\")\n",
    "score = SentimentIntensityAnalyzer().polarity_scores(corpus_string)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Closing Statements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "2afbdf73fbcdecb6073a7d3fe1b85cb5ab8042f504d040d34130e4f01d9f1260"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
